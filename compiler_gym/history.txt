
Подавляющее большинство исследований и инженерных практик сосредоточено на цели повышения производительности, традиционно называемой оптимизацией.


Одно из фундаментальных преимуществ развития компиляторных приложений на основе машинного обучения заключается в том, что оно вынуждает применять эмпирический подход к конструкция компилятора. Новые модели должны быть основаны на эмпирических данных, которые затем могут быть проверены экспертно. Этот цикл – эксперимент – гипотеза – испытание [] хорошо известен в физических науках, но является относительно новым для конструирования компиляторов.

-- Адаптивная и не-итеративная компиляция --
Адаптивная, или управляемая профилированием, оптимизация программ является альтернативой итеративной компиляции, и реализована в значительной части компиляторов общего назначения. Подход основан на профилировании исследуемой программы на отдельных сценариях, с последующим использованием собранных данных о для определения наилучших оптимизаций. Данный подход позволяет достичь отличных результатов на спрофилированных, но может давать непредсказуемые результаты на остальных сценариях, а также является менее прозрачным для исследователя, нежели итеративная компиляция. Трансфер знаний в случае адаптивной компиляции крайне затруднён.

Альтернативный к вышеупомянутым подход не-итеративной компиляции, предсказывающей всю цепочку оптимизаций, до последего времени не получил широкого развития, но решений, основанных преимущественно на обучении с учителем, было представлено .
--
Так или иначе, в последние два десятиления основные усилия исследователей были направлены на преодоление проблемы отсутствия трансфера знаний между экспериментами и на ускорение поиска по пространству оптимизации, с применением различных приближённых методов поиска.
--

Развитие методов машинного обучения в последнее десятилетие привело к совершенствованию и изобретению новых подходов к обозначенным задачам, в совокупности с непрерывной доработкой компиляторных средств и инфраструктур.

Обучение с учителем.
Основным фактором, затрудняющим применение обучения с учителем в данной области, является требование подготовки обучающих выборок: в виду того, что данные и сценарии использования программы в общем случае могут не поддаваться предсказаниям на этапе компиляции, сбор огромной обучающей выборки может оказаться бесполезным для различных задач и сценариев. К примеру, обучение модели по результатам производительности на одной архитектуре может быть не переносимо н другую. Тем не менее, было разработано множество решений, использующих разлиные подходы обучения с учителем: Байесовские сети [,], деревья принятия решения и случайные леса [], обучение метрики [], графовые ядра [], иные методы []. В данной области просматривается тренд интеграции разрабатываемых решений с рекомендательными системами.

Обучение без учителя.
Обучение без учителя в данной области представлено методами кластеризации, позволяющими выделить значимые кластеры трансформаций, которые должны быть упорядочены в подпоследовательности для достижения прироста производительности оптимизируемой программы. Также важность кластеризации обусловлена существенным уменьшением пространства оптимизации. В исследовании [] предложена методология ускорения обучения за счёт применения кластеризации после снижения размерности исходного пространства оптимизации. В работах [170, 171] представлено решение задачи упорядочивания трансформаций с помощью метода выбора, основанного на кластеризации для группировки сходных функций. Следующим широко применяемым в данной задаче классом алгоритмов оптимизации является класс эволюционных, в первую очередь, генетических алгоритмов. Купер и др. [69, 70] решили проблему размера кода генерируемых бинарных файлов с помощью генетического алгоритма, сравнили результаты с итеративным поиском оптимальных последовательностей трансформаций, и пришли к выводу, что для задачи уменьшения размера кода генетические алгоритмы дают результаты, сопоставимые с итеративным подходом при большом числе повторений. Агаков и др. [] адаптировали ряд моделей ускорения исследования пространства оптимизации при итеративной компиляции посредством применения оптимизации с оракулом, и добились достаточно высоких результатов на компиляторе GCC для Intel x86. В целом, в данном направлении наблюдается активность, в основном всязанная с апробацией разработанных способов на новые задачи и компиляторные инфраструктуры. Также следует отметить, что генетические алгоритмы используются в ряде других подходов в качестве референсных решений.

Обучение с подкреплением.
В данном направлении наблюдается наибольшая активность, вследствие общего развития инструментов обучения с подкреплением, а также естественностью трактовки задачи поиска оптимальных последовательностей трансформаций как последовательности шагов агента, получающего награду как приращение целевой метрики -- производительности, размера файла и пр. Принятие решения, какую трансформацию применять, осуществляется на основании наблюдения пространства характеризации программы. Экспериментально установлено [Autophase, CompilerGym], что обучение с подкреплением на данных задачах позволяет достигать результатов, сопоставимых с результатами генетических алгоритмов за существенно меньшее число повторений. Кроме того, репрезентативность характеристик программы также существенно влияет на скорость сходимости и качество получаемых результатов. Комплексное сравнение различных алгоритмов машинного обучения, в особенности, обучения с подкреплением, было проведено в 2022 г. Каммингсом и др. []. Авторами было отмечена важность развития приложений обучения с подкреплением в компиляторных инфраструктурах и выделены основные направления развития, среди которых -- совершенствование представлений программ, доработка компиляторов с целью поддержания интерфейсов для задач машинного обучения, учёт параметров оптимизационных проходов, интеграция машинного обучения в другие задачи компиляторной оптимизации, в особенности, замена эвристик принятия решения на методы машинного обучения. В области последнего направления уже существуют инструменты, основанные на обучении с подкреплением -- MLGO [] и Neurovectorizer []. Тем не менее, интеграция процесса подбора наилучших параметров трансформаций до сих пор является открытой проблемой [].





-- Заключение --
Развитие направления обучения с учителем в данной области существенно ограничено 



Z. Wang and M. O’Boyle, "Machine Learning in Compiler Optimization," in Proceedings of the IEEE, vol. 106, no. 11, pp. 1879-1901, Nov. 2018, doi: 10.1109/JPROC.2018.2817118.

M Haneda. 2005. Optimizing general purpose compiler optimization. Proceedings of the 2nd conference on Computing frontiers (2005), 180–188. http://dl.acm.org/citation.cfm?id=1062293

J Thomson, M O’Boyle, G Fursin, and B Franke. 2009. Reducing training time in a one-shot machine learning-based compiler. International Workshop on Languages and Compilers for Parallel Computing (2009), 399–407. http://link.springer.com/10.1007

Amir Hossein Ashouri, Vittorio Zaccaria, Sotirios Xydis, Gianluca Palermo, and Cristina Silvano. 2013. A framework for Compiler Level statistical analysis over customized VLIW architecture. In VLSI-SoC. 124–129. DOI:http://dx.doi.org/10.1109/VLSI-SoC.2013.6673262

LGA Martins and R Nobre. 2016. Clustering-Based Selection for the Exploration of Compiler Optimization Sequences. ACM Transactions on Architecture and Code Optimization (TACO) 13, 1 (2016), 28. http://dl.acm.org/citation.cfm?id=2883614

Luiz GA Martins, Ricardo Nobre, Alexandre CB Delbem, Eduardo Marques, and João MP Cardoso. 2014. Exploration of compiler optimization sequences using clustering-based selection. In ACM SIGPLAN Notices, Vol. 49. ACM, 63–72

KD Cooper, PJ Schielke, and D Subramanian. 1999. Optimizing for reduced code space using genetic algorithms. ACM
SIGPLAN Notices (1999). http://dl.acm.org/citation.cfm?id=314414

KD Cooper, D Subramanian, and L Torczon. 2002. Adaptive optimizing compilers for the 21st century. The Journal of
Supercomputing (2002). http://link.springer.com/article/10.1023/A:1015729001611

Felix Agakov, Edwin Bonilla, John Cavazos, Björn Franke, Grigori Fursin, Michael FP O’Boyle, John Thomson, Marc Toussaint, and Christopher KI Williams. 2006. Using machine learning to focus iterative optimization. In Proceedings of the International Symposium on Code Generation and Optimization. IEEE Computer Society, 295–305.

S. Kulkarni and J. Cavazos. 2012. Mitigating the compiler optimization phase-ordering problem using machine learning. ACM SIGPLAN Notices (2012). http://dl.acm.org/citation.cfm?id=2384628


